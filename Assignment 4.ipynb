{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97ee90cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf50fa75",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (1,10) doesn't match the broadcast shape (1000,10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26564\\1778360564.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;31m# Update the weights and biases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mU\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[0mV\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[0mW\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdW\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0mb_hidden\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdb_hidden\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (1,10) doesn't match the broadcast shape (1000,10)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set the parameters\n",
    "input_size = 2  # size of input vector\n",
    "hidden_size = 10  # size of hidden layer\n",
    "output_size = 1  # size of output vector\n",
    "sequence_length = 1000  # length of sequence\n",
    "learning_rate = 0.1  # learning rate\n",
    "iterations = 5000  # number of training iterations\n",
    "\n",
    "# Initialize the weights and biases\n",
    "U = np.random.randn(hidden_size, input_size)\n",
    "V = np.random.randn(output_size, hidden_size)\n",
    "W = np.random.randn(hidden_size, hidden_size)\n",
    "b_hidden = np.zeros((hidden_size, 1))\n",
    "b_output = np.zeros((output_size, 1))\n",
    "\n",
    "# Define the activation function (sigmoid)\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Define the derivative of the activation function\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "# Generate the training data\n",
    "X = np.random.randint(low=0, high=10, size=(sequence_length, input_size))\n",
    "Y = np.zeros((sequence_length, output_size))\n",
    "for i in range(sequence_length):\n",
    "    Y[i] = np.sum(X[i])\n",
    "\n",
    "# Train the network\n",
    "for i in range(iterations):\n",
    "    # Initialize the hidden state\n",
    "    h = np.zeros((hidden_size, 1))\n",
    "\n",
    "    # Forward pass\n",
    "    for j in range(sequence_length):\n",
    "        x = X[j].reshape((input_size, 1))\n",
    "        h = sigmoid(np.dot(U, x) + np.dot(W, h) + b_hidden)\n",
    "        y_hat = np.dot(V, h) + b_output\n",
    "\n",
    "    # Calculate the loss and gradients\n",
    "    loss = np.sum((y_hat - Y)**2) / sequence_length\n",
    "    dy_hat = 2 * (y_hat - Y) / sequence_length\n",
    "    dV = np.dot(dy_hat, h.T)\n",
    "    db_output = np.sum(dy_hat, axis=1, keepdims=True)\n",
    "\n",
    "    dU = np.zeros_like(U)\n",
    "    dW = np.zeros_like(W)\n",
    "    db_hidden = np.zeros_like(b_hidden)\n",
    "    dh_next = np.zeros_like(h)\n",
    "\n",
    "    # Backward pass\n",
    "    for j in reversed(range(sequence_length)):\n",
    "        x = X[j].reshape((input_size, 1))\n",
    "        h = sigmoid(np.dot(U, x) + np.dot(W, h) + b_hidden)\n",
    "        y_hat = np.dot(V, h) + b_output\n",
    "\n",
    "        # Calculate the gradients\n",
    "        dy_hat = 2 * (y_hat - Y[j]) / sequence_length\n",
    "        dV += np.dot(dy_hat, h.T)\n",
    "        db_output += dy_hat\n",
    "\n",
    "        dh = np.dot(V.T, dy_hat) + dh_next\n",
    "        dh_raw = sigmoid_derivative(h) * dh\n",
    "        db_hidden += dh_raw\n",
    "        dU += np.dot(dh_raw, x.T)\n",
    "        dW += np.dot(dh_raw, h.T)\n",
    "        dh_next = np.dot(W.T, dh_raw)\n",
    "\n",
    "    # Update the weights and biases\n",
    "    U -= learning_rate * dU\n",
    "    V -= learning_rate * dV\n",
    "    W -= learning_rate * dW\n",
    "    b_hidden -= learning_rate * db_hidden\n",
    "    b_output -= learning_rate * db_output\n",
    "\n",
    "    # Print the loss every 100 iterations\n",
    "    if i % 100 == 0:\n",
    "        print(\"Iteration:\", i, \"Loss:\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b8dab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17220186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "1d07fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(N, seq_len=6, high=1):\n",
    "    \"\"\" A data generator for adding problem.\n",
    "\n",
    "    The data definition strictly follows Quoc V. Le, Navdeep Jaitly, Geoffrey E.\n",
    "    Hintan's paper, A Simple Way to Initialize Recurrent Networks of Rectified\n",
    "    Linear Units.\n",
    "\n",
    "    The single datum entry is a 2D vector with two rows with same length.\n",
    "    The first row is a list of random data; the second row is a list of binary\n",
    "    mask with all ones, except two positions sampled by uniform distribution.\n",
    "    The corresponding label entry is the sum of the masked data. For\n",
    "    example:\n",
    "\n",
    "     input          label\n",
    "     -----          -----\n",
    "    1 4 5 3  ----->   9 (4 + 5)\n",
    "    0 1 1 0\n",
    "\n",
    "    :param N: the number of the entries.\n",
    "    :param seq_len: the length of a single sequence.\n",
    "    :param p: the probability of 1 in generated mask\n",
    "    :param high: the random data is sampled from a [0, high] uniform distribution.\n",
    "    :return: (X, Y), X the data, Y the label.\n",
    "    \"\"\"\n",
    "    X_num = np.random.uniform(low=0, high=high, size=(N, seq_len, 1))\n",
    "    X_mask = np.zeros((N, seq_len, 1))\n",
    "    Y = np.ones((N, 1))\n",
    "    for i in range(N):\n",
    "        # Default uniform distribution on position sampling\n",
    "        positions = np.random.choice(seq_len, size=2, replace=False)\n",
    "        X_mask[i, positions] = 1\n",
    "        X_num = np.round(X_num, 2)\n",
    "        Y[i, 0] = np.round(np.sum(X_num[i, positions]), 2)\n",
    "    X = np.append(X_num, X_mask, axis=2)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1bb2bbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.65, 1.  ],\n",
       "         [0.23, 0.  ],\n",
       "         [0.7 , 0.  ],\n",
       "         [0.11, 0.  ],\n",
       "         [0.31, 0.  ],\n",
       "         [0.28, 1.  ]],\n",
       " \n",
       "        [[0.27, 0.  ],\n",
       "         [0.09, 0.  ],\n",
       "         [0.8 , 0.  ],\n",
       "         [0.69, 1.  ],\n",
       "         [0.98, 0.  ],\n",
       "         [0.1 , 1.  ]]]),\n",
       " array([[0.93],\n",
       "        [0.79]]))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gen(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "05e72ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adding_problem_generator(N):\n",
    "    \"\"\" A data generator for adding problem.\n",
    "\n",
    "    :param N: the number of the entries.\n",
    "    :param seq_len: the length of a single sequence.\n",
    "    :param p: the probability of 1 in generated mask\n",
    "    :param high: the random data is sampled from a [0, high] uniform distribution.\n",
    "    :return: (X, Y), X the data, Y the label.\n",
    "    \"\"\"\n",
    "    X_res, Y_res = [], []\n",
    "    for _ in range(N):\n",
    "        seq_len = np.random.choice(range(3, 11))\n",
    "\n",
    "        X_num = np.random.uniform(low=0, high=1, size=(1, seq_len))\n",
    "        X_num = np.round(X_num, 2)\n",
    "        X_mask = np.zeros((1, seq_len))\n",
    "        # Default uniform distribution on position sampling\n",
    "        positions = np.random.choice(seq_len, size=2, replace=False)\n",
    "        X_mask[0, positions[0]] = 1\n",
    "        X_mask[0, positions[1]] = 1\n",
    "        Y = np.sum([X_num[0, positions[0]], X_num[0, positions[1]]])\n",
    "        Y = np.round(Y, 2)\n",
    "\n",
    "        X = np.append(X_num, X_mask, axis=0)\n",
    "        print(X, Y, sep='\\n')\n",
    "        X_res.append(X.tolist())\n",
    "        Y_res.append(Y.tolist())\n",
    "        \n",
    "    return X_res, Y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9c4b0927",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7  0.94 0.6  0.59 0.45 0.83 0.47 0.61]\n",
      " [0.   0.   1.   0.   0.   0.   1.   0.  ]]\n",
      "1.07\n",
      "[[0.64 0.82 0.37]\n",
      " [1.   1.   0.  ]]\n",
      "1.46\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([[[0.7, 0.94, 0.6, 0.59, 0.45, 0.83, 0.47, 0.61],\n",
       "   [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]],\n",
       "  [[0.64, 0.82, 0.37], [1.0, 1.0, 0.0]]],\n",
       " [1.07, 1.46])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adding_problem_generator(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1a57b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=np.array(a, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5fb9b1b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13596\\53486640.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 1 with size 2"
     ]
    }
   ],
   "source": [
    "ax[:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f33ece1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13596\\1903060523.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_array'"
     ]
    }
   ],
   "source": [
    "a.to_array()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e38cfd5",
   "metadata": {},
   "source": [
    "## Elman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de58ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "wih = np.random.randn(2, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ef6e02d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the Elman network RNN architecture\n",
    "class ElmanNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate):\n",
    "        # Initialize weights for input-to-hidden and hidden-to-hidden connections\n",
    "        self.w_ih = np.random.randn(input_size, hidden_size)\n",
    "        self.w_hh = np.random.randn(hidden_size, hidden_size)\n",
    "        self.b_h = np.zeros((hidden_size, 1))\n",
    "        # Initialize weights for hidden-to-output connections\n",
    "        self.w_ho = np.random.randn(hidden_size, output_size)\n",
    "        self.b_o = np.zeros((output_size, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h = np.zeros((x.shape[0], self.w_hh.shape[0]))\n",
    "        # Initialize list to store hidden states for each time step\n",
    "        hidden_states = []\n",
    "        # Iterate over input sequence and update hidden state and output\n",
    "        for t in range(x.shape[1]):\n",
    "            # Update hidden state using input and previous hidden state\n",
    "            h = np.tanh(np.dot(self.w_ih, x[:,t,:]) + np.dot(self.w_hh, h) + self.b_h)\n",
    "            # Store current hidden state\n",
    "            hidden_states.append(h)\n",
    "        # Compute output using current hidden state\n",
    "        o = np.dot(self.w_ho, h) + self.b_o\n",
    "        # Return final output and list of hidden states\n",
    "        return o, hidden_states\n",
    "\n",
    "    def backward(self, x, y_true, y_pred, hidden_states, learning_rate):\n",
    "        # Initialize gradients with zeros\n",
    "        d_w_ih = np.zeros_like(self.w_ih)\n",
    "        d_w_hh = np.zeros_like(self.w_hh)\n",
    "        d_b_h = np.zeros_like(self.b_h)\n",
    "        d_w_ho = np.zeros_like(self.w_ho)\n",
    "        d_b_o = np.zeros_like(self.b_o)\n",
    "        # Initialize error gradient with zeros\n",
    "        d_error = 0\n",
    "        # Iterate over time steps in reverse order and compute gradients\n",
    "        for t in reversed(range(x.shape[1])):\n",
    "            # Compute error gradient for output layer\n",
    "            d_output = y_true - y_pred\n",
    "            d_error += np.sum(d_output ** 2)\n",
    "            # Compute gradient for hidden-to-output weights and biases\n",
    "            d_w_ho += np.dot(d_output, hidden_states[t].T)\n",
    "            d_b_o += d_output\n",
    "            # Compute gradient for hidden state\n",
    "            d_hidden = np.dot(self.w_ho.T, d_output) + np.dot(self.w_hh.T, d_hidden_next)\n",
    "            # Compute gradient for hidden-to-hidden weights and biases\n",
    "            d_w_hh += np.dot(d_hidden * (1 - hidden_states[t] ** 2), hidden_states[t-1].T)\n",
    "            d_b_h += d_hidden * (1 - hidden_states[t] ** 2)\n",
    "            # Compute gradient for input-to-hidden weights and biases\n",
    "            d_w_ih += np.dot(d_hidden * (1 - hidden_states[t] ** 2), x[:,t].T)\n",
    "        # Update weights and biases using gradients and learning rate\n",
    "        self.w_ih += learning_rate * d_w_ih\n",
    "        self.w_hh += learning_rate * d_w_hh\n",
    "        self.b_h += learning_rate * d_b_h\n",
    "        self.w_ho += learning_rate * d_w_ho\n",
    "        self.b_o += learning_rate * d_b_o\n",
    "        # Return total error gradient\n",
    "        return d_error\n",
    "\n",
    "# Define parameters for the Elman network RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "50bb9817",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y = data_gen(100)\n",
    "val_X, val_Y = data_gen(400)\n",
    "test_X, test_Y = data_gen(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e56967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "6d22ef66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,16) and (100,2) not aligned: 16 (dim 1) != 100 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13596\\2032872219.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m#     y_pred = rnn.forward(batch_X)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m# Compute loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13596\\3527148662.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;31m# Update hidden state using input and previous hidden state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_ih\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_hh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[1;31m# Store current hidden state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (2,16) and (100,2) not aligned: 16 (dim 1) != 100 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters\n",
    "hidden_size = 16\n",
    "learning_rate = 0.1\n",
    "num_epochs = 100\n",
    "#batch_size = 16\n",
    "#num_batches = int(len(train_X) / batch_size)\n",
    "\n",
    "# Initialize Elman network RNN\n",
    "rnn = ElmanNetwork(input_size=2, hidden_size=hidden_size, output_size=1, learning_rate=learning_rate)\n",
    "\n",
    "# Train the network\n",
    "for epoch in range(num_epochs):\n",
    "    # Shuffle the training set\n",
    "    #indices = np.random.permutation(len(train_X))\n",
    "    #train_X = train_X[indices]\n",
    "    #train_Y = train_Y[indices]\n",
    "\n",
    "    # Initialize total loss for epoch\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    # Train on batches\n",
    "    #for batch in range(num_batches):\n",
    "    # Get batch inputs and targets\n",
    "    #start = batch * batch_size\n",
    "    #end = start + batch_size\n",
    "    #batch_X = train_X[start:end]\n",
    "    #batch_Y = train_Y[start:end]\n",
    "\n",
    "    # Forward pass\n",
    "#     y_pred = rnn.forward(batch_X)\n",
    "    y_pred = rnn.forward(train_X)\n",
    "\n",
    "    # Compute loss\n",
    "#     loss = mean_squared_error(batch_Y, y_pred)\n",
    "    loss = mean_squared_error(train_Y, y_pred)\n",
    "    epoch_loss += loss\n",
    "\n",
    "    # Backward pass\n",
    "#     rnn.backward(batch_X, batch_Y, y_pred)\n",
    "    rnn.backward(train_X, train_Y, y_pred)\n",
    "        \n",
    "    # Compute average epoch loss\n",
    "    #epoch_loss /= num_batches\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    val_Y_pred = rnn.forward(val_X)\n",
    "    val_loss = mean_squared_error(val_Y, val_Y_pred)\n",
    "\n",
    "    # Print epoch results\n",
    "    print(\"Epoch {}/{}: loss={:.4f}, val_loss={:.4f}\".format(epoch+1, num_epochs, epoch_loss, val_loss))\n",
    "\n",
    "    # Check stopping criterion\n",
    "    if val_loss < 1e-4:\n",
    "        print(\"Stopping criterion reached!\")\n",
    "        break\n",
    "\n",
    "# Evaluate on test set\n",
    "test_Y_pred = rnn.forward(test_X)\n",
    "test_loss = mean_squared_error(test_Y, test_Y_pred)\n",
    "print(\"Test loss: {:.4f}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058f437a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e62706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80635194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "2cdb0016",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'minpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13596\\3890277655.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mminpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mminpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mminpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelBase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mminpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSolver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mminpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNDArrayIter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'minpy'"
     ]
    }
   ],
   "source": [
    "import minpy.numpy as np\n",
    "from minpy.nn import layers\n",
    "from minpy.nn.model import ModelBase\n",
    "from minpy.nn.solver import Solver\n",
    "from minpy.nn.io import NDArrayIter\n",
    "from examples.utils.data_utils import adding_problem_generator as data_gen\n",
    "\n",
    "\n",
    "class RNNNet(ModelBase):\n",
    "    def __init__(self,\n",
    "                 batch_size=100,\n",
    "                 input_size=2,  # input dimension\n",
    "                 hidden_size=64,\n",
    "                 num_classes=1):\n",
    "        super(RNNNet, self).__init__()\n",
    "        self.add_param(name='Wx', shape=(input_size, hidden_size))\\\n",
    "            .add_param(name='Wh', shape=(hidden_size, hidden_size))\\\n",
    "            .add_param(name='b', shape=(hidden_size,))\\\n",
    "            .add_param(name='Wa', shape=(hidden_size, num_classes))\\\n",
    "            .add_param(name='ba', shape=(num_classes,))\n",
    "\n",
    "    def forward(self, X, mode):\n",
    "        seq_len = X.shape[1]\n",
    "        batch_size = X.shape[0]\n",
    "        hidden_size = self.params['Wh'].shape[0]\n",
    "        h = np.zeros((batch_size, hidden_size))\n",
    "        for t in xrange(seq_len):\n",
    "            h = layers.rnn_step(X[:, t, :], h, self.params['Wx'],\n",
    "                                self.params['Wh'], self.params['b'])\n",
    "        y = layers.affine(h, self.params['Wa'], self.params['ba'])\n",
    "        return y\n",
    "\n",
    "    def loss(self, predict, y):\n",
    "        return layers.l2_loss(predict, y)\n",
    "\n",
    "\n",
    "def main():\n",
    "    model = RNNNet()\n",
    "    x_train, y_train = data_gen(10000)\n",
    "    x_test, y_test = data_gen(1000)\n",
    "\n",
    "    train_dataiter = NDArrayIter(x_train,\n",
    "                                 y_train,\n",
    "                                 batch_size=100,\n",
    "                                 shuffle=True)\n",
    "\n",
    "    test_dataiter = NDArrayIter(x_test,\n",
    "                                y_test,\n",
    "                                batch_size=100,\n",
    "                                shuffle=False)\n",
    "\n",
    "    solver = Solver(model,\n",
    "                    train_dataiter,\n",
    "                    test_dataiter,\n",
    "                    num_epochs=10,\n",
    "                    init_rule='xavier',\n",
    "                    update_rule='adam',\n",
    "                    task_type='regression',\n",
    "                    verbose=True,\n",
    "                    print_every=20)\n",
    "    solver.init()\n",
    "    solver.train()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17fd404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd9f2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c052fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a78446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a7ff8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0cf41d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2a14a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcd67d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025179fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
